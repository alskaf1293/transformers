# Transformers from scratch
This is me implementing transformers from scratch. 
Given how ubiquitous these models have been over the past few years, it makes sense to both get a really good understanding of it
as well as know at a low level (Yes, Pytorch is low level for me) how it works, as since its inception, it largely renders RNN's and
LSTM's obselete because of its self-attention mechanism allowing limitless knowledge of previously seen inputs.
